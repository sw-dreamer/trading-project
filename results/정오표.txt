머신러닝 정오표
(p116) 아래에서 5번째 줄에 “당연하지만 열을 모두 더하면”을 “당연하지만 각 행의 열을 모두 더하면”으로 수정합니다.
(p111) 아래에서 16번째 줄에 “각 에포크의 평균 제곱 오차 손실 함수 값”을 “각 에포크의 로지스틱 손실 함수 값”으로 수정합니다.
(p664) 위에서 9번째 줄에 >>> from torch.utils.data import Dataset을 삭제합니다.
(p476) 위에서 3번째 줄의 공식에서 \sum_i^n를 \sum_{i=1}^n로 수정합니다.
(p653) 위에서 9번째 줄에 “크기는 10x6이 됩니다”를 “크기는 10x3이 됩니다”로 수정합니다.
(p121) 위에서 3번째 줄에 “가중치가 \phi에 가까워지면”을 “가중치가 0에 가까워지면”으로 수정합니다.(가*다 님)
(p376) 그림 9-2 위 두 번째 줄 “여기에서 w_0은 y 축의 절편이고 x_0=1입니다” 문장을 삭제합니다.(가*다 님)
(p453) 위에서 2번째 줄에 w_{j,k}^{(l)}을 w_{j,k}^{(l+1)}로 수정합니다.(가*다 님)
(p455) 아래에서 7번째 줄에 “z^{(in)}은 절편을 더한 1\times m 차원 특성 벡터입니다. W^{(h)}는 m \times d 차원의 가중치 행렬입니다”를 “x^{(in)}는 1\times m 차원 특성 벡터입니다. W^{(h)}는 d \times m 차원의 가중치 행렬입니다”로 수정합니다.(가*다 님)
(p461) 위에서 2번째 줄에 “다음 코드는 5만 5,000개의 이미지를, 훈련에 5,000개의 이미지를 사용하고 검증에 10,000개의 이미지를 테스트에 사용하도록 데이터셋을 분할합니다”를 “다음 코드는 5만 5,000개의 이미지를 훈련에, 5,000개의 이미지를 검증에, 10,000개의 이미지를 테스트에 사용하도록 데이터셋을 분할합니다”로 수정합니다.(가*다 님)
(p476) 위에서 7번째 줄에 \dfrac{\partial L}{\partial w_{j,l}^{(l)}}을 \dfrac{\partial L}{\partial w_{j,k}^{(l)}}로 수정합니다.(가*다 님)
(p480) 위에서 8번째 줄 \dfrac{\partial L}{\partial a_1^{(out)}} 수식과 아래에서 3번째 줄 \dfrac{\partial L}{\partial w_{1,1}^{(out)}} 수식에서 2(a_1^{(out)}-y)를 2(a_1^{(out)}-y_1)로 수정합니다. 위에서 10번째 줄 \dfrac{\partial a_1^{(out)}}{\partial z_1^{(out)}} 수식에서 e^{z_1^{(out)}}을 모두 e^{-z_1^{(out)}}로 수정합니다.(가*다 님)
(p482) 아래에서 8번째 줄에서 \dfrac{\partial L}{\partial w_{1,1}^{(out)}}을 \dfrac{\partial L}{\partial w_{1,1}^{(h)}}로 수정합니다.(가*다 님)
(p139) 페이지 중간 코드 블록에서 feature_names 변수를 정의하는 부분을 다음과 같이 수정합니다.
feature_names = ['Petal length', 'Petal width']
그림 3-23에서 Sepal length를 Petal length로 Sepal width를 Petal width로 수정합니다.(유*우 님)
(p180) 위에서 7번째 줄에서 “2장에서 사용했던 제곱 오차합(SSE) 손실 함수를”을 “2장에서 사용했던 평균 제곱 오차(MSE) 손실 함수를”로 정정합니다.(유*우 님)
(p471) 그림 11-7 위 마지막 코드 라인에서 plt.show(loc='lower right')를 plt.show()로 정정합니다.(한*석 님)
(p530) 아래에서 8번째 줄에 torch. ()를 torch.relu()로 정정합니다.(한*석 님)
(p549) 위에서 9번째 줄에 ‘세 개의 은닉층으로 구성된’을 ‘두 개의 은닉층으로 구성된’으로 수정합니다.(한*석 님)
(p558) 아래에서 7번째 줄에 dataset_path = dataset_path.replace("auto+mpg.zip", "auto-mpg.data")를 url = dataset_path.replace("auto+mpg.zip", "auto-mpg.data")로 정정합니다.(한*석 님)
(p638) 그림 15-6에서 맨 오른쪽 최종 출력의 공식에서 W_{hy}를 W_{ho}로 수정합니다.(한*석 님)
(p214) 역주 노트 위에서 3번째 줄과 10번째 줄 아래 pca.fit(X_train_std)를 추가합니다.(한*석 님)
(p242) 그림 6-2 바로 위의 코드 pipe를 pipe_lr로 수정합니다.(한*석 님)
(p247) 페이지 위쪽에 있는 코드 출력에서 “폴드: 1″~”폴드: 9″를 “폴드: 01″~”폴드: 09″로 수정합니다.(한*석 님)
(p69) 6번 주석의 첫 번째 줄 끝에 \eta(y^{(1)}-\sigma(0)x^{(1)})을 \eta(y^{(1)}-\sigma(0))x^{(1)}로 정정합니다.(최*별 님)
(p429) 그림 10-6에서 클러스터 1과 2를 바꿉니다. 깃허브(https://github.com/rickiepark/ml-with-pytorch/blob/main/ch10/ch10.ipynb) 노트북의 결과를 참고하세요.(김*주 님)
(p422) 위에서 13번째 줄에 “1보다 크거가 같으며“를 “1보다 크며“로 수정합니다.(최*별 님)
(p515) 위에서 9번째 줄부터 시작하는 with 문의 블록을 for 블록 안에 포함되도록 들여쓰기 합니다. 깃허브 노트북을 참고하세요(https://bit.ly/3Cxa8g3).(최*별 님)
(p564) 위에서 11번째 줄과 15번째 줄에서 download=False를 download=True로 수정합니다.